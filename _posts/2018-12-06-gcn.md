---
layout:     post
title:      【Draft】GCN理论和应用
subtitle:   图卷积网络的来龙去脉
date:       2018-12-06
author:     Oscar Zhang
header-style:   text
catalog:    true
mathjax:    true
tags:
    - Coding
    - Python
---

## 核心：图卷积

在计算机视觉领域，Convolutional Neural Network(CNN)已经取得了巨大成就，主要针对Euclidean Structure的数据（图像属此类型）。

![][1]

在Topological Structure（拓扑结构）数据中，相应的工具则是Graph Convolutional Network，可以应对更广义的结构数据。

![][2]

GCN在ICLR 2017由[T.Kipf](https://tkipf.github.io/graph-convolutional-networks/), M.Welling正式提出([Semi-supervised Classification with Graph Convolutional Networks](https://arxiv.org/pdf/1609.02907.pdf))。

![][3]

先介绍一下图的基础知识。对于一个图：

![][10]

对应的数学表示为：

| Degree Matrix $$D$$|  Adjacency Matrix $$A$$ | Laplacian Matrix $$L$$ |
| :-----:   | :----: | :----: |
| $$ \begin{pmatrix} 2 &  &  &  &  & \\  & 3 &  &  &  & \\  &  & 2 &  &  & \\  &  &  & 3 &  & \\  &  &  &  & 3 & \\  &  &  &  &  & 1 \end{pmatrix} $$ |$$\begin{pmatrix} & 1 &  &  & 1 & \\ 1 &  & 1 &  & 1 & \\  & 1 &  & 1 &  & \\  &  & 1 &  & 1 & 1\\ 1 & 1 &  & 1 &  & \\  &  &  & 1 &  & \end{pmatrix}$$| $$\begin{pmatrix}2 & -1 &  &  & -1 & \\ -1 & 3 & -1 &  & -1 & \\  & -1 & 2 & -1 &  & \\  &  & -1 & 3 & -1 & -1\\ -1 & -1 &  & -1 & 3 & \\  &  &  & -1 &  & 1\end{pmatrix}$$|

在GCN文中一开始便给出了核心，每两层直接的递推公式：

$$H^{(l+l)}=\sigma(\tilde{D}^ {-\frac{1}{2}}\tilde{A}\tilde{D}^ {-\frac{1}{2}}H^{(l)}W^{(l)})$$

其中，$$\tilde {A}$$是$$A$$加上单位对角矩阵；$$\tilde {D}$$是相应的度；$$H^{(l)}$$为第$$l$$层以各节点特征为行向量的矩阵（$$H^{(0)}$$为输入）；$$W$$为权重矩阵，每层不同，是训练最终要得到的参数；$$\sigma$$是激活函数。   

## 图卷积的来龙

我看到卷积公式之后，内心是崩溃的：为什么是这样一个公式，有什么道理吗？总不能是试来的吧？      
抱着为什么的疑问，我对其来龙进行了简要的学习，这个过程还是蛮有意思的。下面是一个简要介绍，省略了数学的性质和推导，主要看中心思想。
众所周知，卷积是信号处理中的概念，与Fourier transform息息相关。GCN的概念也是从此推广而来。     

#### 图上的傅立叶变换

首先，图的Laplacian matrix $$L$$是半正定对称矩阵，利用其性质，可以进行矩阵分解

$$L=U \begin{pmatrix}\lambda_{1} &  & \\ & \ddots & \\ &  & \lambda_{n}\end{pmatrix} U^{-1}$$

其中，$$\begin{pmatrix}\lambda_{1} &  & \\ & \ddots & \\ &  & \lambda_{n}\end{pmatrix}$$是$$L$$的$$n$$个特征值组成的对角阵，$$U=(\overrightarrow{u_{1}},\overrightarrow{u_{2}},\dots{},\overrightarrow{u_{n}})$$是列向量为单位特征向量的矩阵。

因为$$U$$是正交矩阵，有$$UU^{T}=E$$,所以有：

$$L=U \begin{pmatrix}\lambda_{1} &  & \\ & \ddots & \\ &  & \lambda_{n}\end{pmatrix} U^{T}$$

如何利用包含图结构的$$L$$，和代表其特性的的$$\begin{pmatrix}\lambda_{1} &  & \\ & \ddots & \\ &  & \lambda_{n}\end{pmatrix}$$和$$U$$推导出图卷积的过程？

故事要从Fourier transform说起。傅立叶正变换：

$$F(\omega)=\mathcal{F}[f(t)]=\int f(t)e^{-i \omega t}\,dt$$

公式很复杂，这里只说它的思想。傅立叶变换用形象一些的图表示为：

![][5]

傅立叶逆变换，就是上图的逆向过程：

$$F(\omega)=\mathcal{F}[f(t)]=\frac {1}{2\pi} \int f(t)e^{i \omega t}\,dt$$     

从物理角度理解傅里叶变换是以一组特殊的函数为正交基，对原函数进行线性变换，物理意义便是原函数在各组基函数的投影。这跟拉普拉斯矩阵的特征值分解有相同的本质。       
如果将$$[f(1), \dots,f(N)]$$和$$[u_{l}(1), \dots,u_{l}(N)]$$看成时间信号，就可以套用傅里叶变换了。     

类推Topological Graph上的傅立叶变换：

$$\hat{f}(\lambda_{l})=\sum_{i=1}^{n}f(i)u_{l}^{*}(i)$$
    
矩阵形式为

$$\hat{f}=U^{T}f$$         

具体来说，就是     

$$\begin{pmatrix}\hat{f}({\lambda_{1}})\\ \hat{f}({\lambda_{2}})\\\vdots\\ \hat{f}({\lambda_{N}})\end{pmatrix}=\begin{pmatrix}
u_{1}(1) & u_{1}(2) & \dots & u_{1}(N)\\ 
u_{2}(1) & u_{2}(2) & \dots & u_{2}(N)\\ 
\vdots & \vdots & \ddots & \vdots \\ 
u_{N}(1) & u_{N}(2) & \dots & u_{N}(N)
\end{pmatrix}\begin{pmatrix}f(1)\\ f(2)\\ \vdots\\ f(N)\end{pmatrix}$$   
   
其中，$$f(n)$$是拓扑图中第n个节点的特征，$$\hat{f}({\lambda_{n}})$$是在特征值的域上的特征。         
相应的逆变换为：

$$\begin{pmatrix}f(1)\\ f(2)\\ \vdots\\ f(N)\end{pmatrix}=\begin{pmatrix}
u_{1}(1) & u_{2}(1) & \dots & u_{N}(1)\\ 
u_{1}(2) & u_{2}(2) & \dots & u_{N}(2)\\ 
\vdots & \vdots & \ddots & \vdots \\ 
u_{1}(N) & u_{2}(N) & \dots & u_{N}(N)
\end{pmatrix}\begin{pmatrix}\hat{f}({\lambda_{1}})\\ \hat{f}({\lambda_{2}})\\\vdots\\ \hat{f}({\lambda_{N}})\end{pmatrix}$$

#### 图上的卷积

傅里叶卷积：

$$\mathcal{f*h} = \mathcal{F}^{-1}[\hat{\mathcal{f}}(\omega)\hat{\mathcal{h}}(\omega)]=\frac{1}{2\pi}\int \hat{\mathcal{f}}(\omega)\hat{\mathcal{h}}(\omega)e^{i\omega t}\,d\omega$$

推广到图卷积：

$$(\mathcal{f*h})_{G}(i)=\sum_{l=1}^{N} \hat{\mathcal{f}}({\lambda_{l}})\hat{\mathcal{h}}({\lambda_{l}})u_{l}(i)$$

矩阵形式

$$(\mathcal{f*h})_{G}=U \begin{pmatrix}\hat{h}(\lambda_{1}) &  & \\ & \ddots & \\ &  & \hat{h}(\lambda_{n})\end{pmatrix} U^{T}f$$

[设计核函数](http://papers.nips.cc/paper/6081-convolutional-neural-networks-on-graphs-with-fast-localized-spectral-filtering.pdf)   $$\hat{h}(\lambda_{n})$$    为   $$\sum_{j=0}^{K-1}\alpha_{j}\lambda_{n}^{j}$$

则有

$$\begin{align*}
output &= \sigma \begin{pmatrix}
U \begin{pmatrix}\sum_{j=0}^{K-1}\alpha_{j}\lambda_{1}^{j} &  & \\ & \ddots & \\ &  & \sum_{j=0}^{K-1}\alpha_{j}\lambda_{n}^{j}\end{pmatrix} U^{T}f
\end{pmatrix} \\ 
&=\sigma \begin{pmatrix} U\sum_{j=0}^{K-1}\alpha_{j}\Lambda^{j}U^{T}f \end{pmatrix}\\
&=\sigma \begin{pmatrix}\sum_{j=0}^{K-1}\alpha_{j}U\Lambda^{j}U^{T}f \end{pmatrix}\\
&=\sigma \begin{pmatrix}\sum_{j=0}^{K-1}\alpha_{j}U\Lambda^{j-1}U^{T}U\Lambda^{1}U^{T}f \end{pmatrix}\\
&=\sigma \begin{pmatrix}\sum_{j=0}^{K-1}\alpha_{j}U\Lambda^{j-1}U^{T}U\begin{pmatrix}\lambda_{1} &  & \\ & \ddots & \\ &  & \lambda_{n}\end{pmatrix}U^{T}f \end{pmatrix}  \\ 
&=\sigma \begin{pmatrix}\sum_{j=0}^{K-1}\alpha_{j}U\Lambda^{j-1}U^{T}Lf \end{pmatrix}\\
&=\sigma \begin{pmatrix}\sum_{j=0}^{K-1}\alpha_{j}L^{j}f \end{pmatrix}
\end{align*}$$

- 可以看出，最终的计算公式具有Spatial Localization

![][6]
![][7]

再结合$$\tilde{D}^ {-\frac{1}{2}}\tilde{A}\tilde{D}^ {-\frac{1}{2}}$$是拉普拉斯矩阵$$L$$的一种变形。所以，$$H^{(l+l)}=\sigma(\tilde{D}^ {-\frac{1}{2}}\tilde{A}\tilde{D}^ {-\frac{1}{2}}H^{(l)}W^{(l)})$$就不难理解了。

### 图卷积的应用

#### 原文例：聚类

![][2]

上图是一个社交网络（空手道俱乐部），节点表示成员的特征，边表示有社交关系，颜色代表了他们所属的小团体。不依靠节点的特征，只通过图，在随机初始化权重之后，经过两次前向传播，可以大致将成员分对。

#### 原文例：半监督学习

![][8]

每类只只标记一个样本（图例是四类），将网络最终的输出做训练，即只对这四个样本做训练。剩下的样本在训练完成之后的输出即是预测。

#### 视频动作识别

[Wang, Xiaolong, and Abhinav Gupta. "Videos as Space-Time Region Graphs." ECCV, 2018).](https://arxiv.org/pdf/1806.01810.pdf)

![][9]

在前向传播的过程中，插入GCN模块。如图例，对连续四帧监测到的目标，建立图。可以将目标之间的关联信息加以利用，增强目标识别的效果。


[1]: https://raw.githubusercontent.com/zbhoscar/zbhoscar.github.io/master/img/in-post/post-gcn/1.jpg
[2]: https://raw.githubusercontent.com/zbhoscar/zbhoscar.github.io/master/img/in-post/post-gcn/2.jpg
[3]: https://raw.githubusercontent.com/zbhoscar/zbhoscar.github.io/master/img/in-post/post-gcn/3.jpg
[4]: https://raw.githubusercontent.com/zbhoscar/zbhoscar.github.io/master/img/in-post/post-gcn/4.jpg
[5]: https://raw.githubusercontent.com/zbhoscar/zbhoscar.github.io/master/img/in-post/post-gcn/5.jpg
[6]: https://raw.githubusercontent.com/zbhoscar/zbhoscar.github.io/master/img/in-post/post-gcn/6.jpg
[7]: https://raw.githubusercontent.com/zbhoscar/zbhoscar.github.io/master/img/in-post/post-gcn/7.jpg
[8]: https://raw.githubusercontent.com/zbhoscar/zbhoscar.github.io/master/img/in-post/post-gcn/8.jpg
[9]: https://raw.githubusercontent.com/zbhoscar/zbhoscar.github.io/master/img/in-post/post-gcn/9.jpg
[10]: https://raw.githubusercontent.com/zbhoscar/zbhoscar.github.io/master/img/in-post/post-gcn/10.jpg
